#### general settings
name: train_small_model
scale: 2
type : mse


#### datasets
datasets:
  train:
    name: train
    mode: LQGT
    noise_rate_random: false
    noise_needed: true
    noise_data: "../../storage/data/df2k/jpeg_noise/Corrupted_noise/" 
    dataroot_GT: ../../storage/data/df2k/HR
    dataroot_LQ: ../../storage/data/df2k/LRx2
    use_shuffle: false
    n_workers: 4  # per GPU
    batch_size: 64
    GT_size: 128
    color: RGB
  val:
    name: validation
    mode: LQGT
    noise_rate_random: true
    noise_needed: false
    noise_data: ../../storage/data/df2k/Corrupted_noise/
    dataroot_GT: ../../storage/data/df2k/HR
    dataroot_LQ: ../../storage/data/df2k/LRx4
    use_shuffle: false
    n_workers: 4  # per GPU
    batch_size: 1
    GT_size: 128 
    color: RGB
#### network structures
structure:
  network_G:
    which_model_G: imdn_rte
    in_nc: 3
    out_nc: 3
    nf: 20
    num_modules: 5

#### path
pretraining_settings:
  network_G: 
    want_load: true
    pretrained_model_path:  "../checkpoints/imdn_rte_20_5_mse_one.pt"
    key: "generator_state_dict"
    strict_load:  true
  
#epoch settings
epoch_settings:
  total_epochs: 100
  resume_state_epoch: ~
  resume_state_batch: ~

#### training settings: learning rate scheme, loss
train_settings:
  lr_G: !!float 1e-3  
  lr_step_decay: 100
  weight_decay_G: !!float 0
  beta1_G: 0.9
  beta2_G: 0.999
  pixel_criterion: l1  #l1 | l2  #CharbonnierLoss
  top_score:  !!int -1
  
  sample_interval: ~
  save_checkpoint_folder_path: "../checkpoints"
  save_checkpoint_file_name: "imdn_rte_20_5_mse_one.pt"
  save_bestmodel_file_name: "imdn_rte_20_5_mse_one.pt"
